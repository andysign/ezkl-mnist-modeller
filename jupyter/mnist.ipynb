{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca979153-3ae5-4664-8442-c495fc0af695",
   "metadata": {},
   "source": [
    "## Mnist Classifier\n",
    "\n",
    "Here we demonstrate how to use the EZKL package to build an MNIST classifier for handrawn digit recognition. This compiles the trained network into both .onnx representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c70cef-5fef-412a-b076-45be9f6d5fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        # Convolutional encoder\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)  # 1 input channel, 6 output channels, 5x5 kernel\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5) # 6 input channels, 16 output channels, 5x5 kernel\n",
    "\n",
    "        # Fully connected layers / Dense block\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)         # 120 inputs, 84 outputs\n",
    "        self.fc3 = nn.Linear(84, 10)          # 84 inputs, 10 outputs (number of classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutional block\n",
    "        x = F.avg_pool2d(F.sigmoid(self.conv1(x)), (2, 2)) # Convolution -> Sigmoid -> Avg Pool\n",
    "        x = F.avg_pool2d(F.sigmoid(self.conv2(x)), (2, 2)) # Convolution -> Sigmoid -> Avg Pool\n",
    "\n",
    "        # Flattening\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Fully connected layers\n",
    "        x = F.sigmoid(self.fc1(x))\n",
    "        x = F.sigmoid(self.fc2(x))\n",
    "        x = self.fc3(x)  # No activation function here, will use CrossEntropyLoss later\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e097c390-4f6e-4464-97f8-b521188317a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torchvision.datasets import mnist\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam  # Import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "def normalize_img(image, label):\n",
    "  return torch.round(image), label\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "batch_size = 256\n",
    "\n",
    "is_needs_downloading = True\n",
    "if (os.path.exists('mnist-train-n-test.tar.gz')):\n",
    "    print('Found local zip. Unzipping MNIST train and test...')\n",
    "    os.system('tar -xzf mnist-train-n-test.tar.gz')\n",
    "    is_needs_downloading = False\n",
    "\n",
    "train_dataset = mnist.MNIST(root='./train', train=True, transform=ToTensor(), download=is_needs_downloading)\n",
    "test_dataset = mnist.MNIST(root='./test', train=False, transform=ToTensor(), download=is_needs_downloading)\n",
    "\n",
    "train_dataset_all = train_dataset # torch.utils.data.Subset(train_dataset, list(range(0, len(train_dataset), 1)))\n",
    "train_dataset_subset = torch.utils.data.Subset(train_dataset, list(range(1, len(train_dataset), 2)))\n",
    "test_dataset_all = test_dataset # torch.utils.data.Subset(train_dataset, list(range(0, len(train_dataset), 1)))\n",
    "test_dataset_subset = torch.utils.data.Subset(train_dataset, list(range(1, len(train_dataset), 2)))\n",
    "\n",
    "train_loader = DataLoader(train_dataset_all, batch_size=batch_size) # train_dataset_subset\n",
    "test_loader = DataLoader(test_dataset_all, batch_size=batch_size) # test_dataset_subset\n",
    "model = LeNet().to(device)\n",
    "adam = Adam(model.parameters())  # Using Adam with a learning rate of 1e-3\n",
    "loss_fn = CrossEntropyLoss()\n",
    "all_epoch = 25\n",
    "prev_acc = 0\n",
    "\n",
    "if (os.path.exists('models-pkl.tar.gz')):\n",
    "    print('Found local zip. Unzipping MNIST model(s)...')\n",
    "    os.system('tar -xzf models-pkl.tar.gz')\n",
    "    all_epoch = 0\n",
    "\n",
    "for current_epoch in range(all_epoch):\n",
    "    model.train()\n",
    "    for idx, (train_x, train_label) in enumerate(train_loader):\n",
    "        train_x = train_x.to(device)\n",
    "        # normalize the image to 0 or 1 to reflect the inputs from the drawing board\n",
    "        train_x = train_x.round()\n",
    "        train_label = train_label.to(device)\n",
    "        adam.zero_grad()  # Use adam optimizer\n",
    "        predict_y = model(train_x.float())\n",
    "        loss = loss_fn(predict_y, train_label.long())\n",
    "        loss.backward()\n",
    "        adam.step()  # Use adam optimizer\n",
    "    all_correct_num = 0\n",
    "    all_sample_num = 0\n",
    "    model.eval()\n",
    "\n",
    "    for idx, (test_x, test_label) in enumerate(test_loader):\n",
    "        test_x = test_x.to(device)\n",
    "         # normalize the image to 0 or 1 to reflect the inputs from the drawing board\n",
    "        test_x = test_x.round()\n",
    "        test_label = test_label.to(device)\n",
    "        predict_y = model(test_x.float()).detach()\n",
    "        predict_y = torch.argmax(predict_y, dim=-1)\n",
    "        current_correct_num = predict_y == test_label\n",
    "        all_correct_num += np.sum(current_correct_num.to('cpu').numpy(), axis=-1)\n",
    "        all_sample_num += current_correct_num.shape[0]\n",
    "    acc = all_correct_num / all_sample_num\n",
    "    print('test accuracy: {:.3f}'.format(acc), flush=True)\n",
    "    if not os.path.isdir(\"models_good\"):\n",
    "        os.mkdir(\"models_good\")\n",
    "    torch.save(model, 'models_good/mnist_{:.3f}.pkl'.format(acc))\n",
    "    prev_acc = acc\n",
    "\n",
    "if (os.path.exists('models-pkl.tar.gz')):\n",
    "    print('Loading MNIST model from disk...')\n",
    "    model = torch.load(os.path.join('models_good', os.listdir('./models_good/')[-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdfe32a-7194-4e52-8ff7-e7d6fc120d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "model_path = os.path.join('network_good.onnx')\n",
    "data_path = os.path.join('input.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61daae4f-7d14-4e46-b4eb-8fbad0501d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# # Fetch a single data point from the train_dataset\n",
    "# # Ensure train_dataset is already loaded and accessible\n",
    "train_data_point, _ = next(iter(train_dataset))\n",
    "train_data_point = train_data_point.unsqueeze(0)  # Add a batch dimension\n",
    "\n",
    "# Verify the device (CPU or CUDA) and transfer the data point to the same device as the model\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "train_data_point = train_data_point.to(device)\n",
    "\n",
    "# # Export the model to ONNX format\n",
    "torch.onnx.export(model, train_data_point, model_path, export_params=True, opset_version=12, do_constant_folding=True, input_names=['input_0'], output_names=['output'])\n",
    "\n",
    "# Convert the tensor to numpy array and reshape it for JSON serialization\n",
    "x = train_data_point.cpu().detach().numpy().reshape([-1]).tolist()\n",
    "data = {'input_data': [x]}\n",
    "with open('input.json', 'w') as f:\n",
    "    json.dump(data, f)\n",
    "\n",
    "print(f\"Model exported to {model_path} and input data saved to input.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750523ea-5821-4c46-a486-3d7c6ad7f8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture set of data points\n",
    "num_data_points = 15\n",
    "\n",
    "# Fetch 30 data points from the train_dataset\n",
    "data_points = []\n",
    "for i, (data_point, _) in enumerate(train_dataset):\n",
    "    if i >= num_data_points:\n",
    "        break\n",
    "    data_points.append(data_point)\n",
    "\n",
    "# Stack the data points to create a batch\n",
    "train_data_batch = torch.stack(data_points)\n",
    "\n",
    "# Add a batch dimension if not already present\n",
    "if train_data_batch.dim() == 3:\n",
    "    train_data_batch = train_data_batch.unsqueeze(0)\n",
    "\n",
    "x = train_data_batch.cpu().detach().numpy().reshape([-1]).tolist()\n",
    "\n",
    "data = dict(input_data = [x])\n",
    "\n",
    "cal_path = os.path.join('cal_data.json')\n",
    "\n",
    "# Serialize data into file:\n",
    "json.dump( data, open(cal_path, 'w' ))\n",
    "print(f\"Calibration data exported to {cal_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631f5520-22c5-451e-bd1f-a7dc74b06d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See a sample image\n",
    "import matplotlib.pyplot as plt\n",
    "examples = iter(test_loader); example_data, example_targets = next(examples)\n",
    "plt.imshow(example_data[0][0], cmap='gray')\n",
    "plt.show()\n",
    "# Test one input\n",
    "outputs = model(example_data)\n",
    "# output_tensor  = output.clone().detach() # torch.tensor(output).squeeze(0)\n",
    "pred = outputs.argmax(1, keepdim=True)[0]\n",
    "print('predicted_digit:', pred.tolist())\n",
    "# outputs.max(1)[0]\n",
    "\n",
    "l = outputs.softmax(dim=1)[0].tolist()\n",
    "for e in l: print(format(e, 'f'))\n",
    "print('---')\n",
    "for e in outputs[0].tolist(): print(e/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf3d06e-1211-4717-bf6c-794a92ce65bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the bad model (network_bad)\n",
    "%time\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torchvision.datasets import mnist\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam  # Import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "def normalize_img(image, label):\n",
    "  return torch.round(image), label\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "batch_size = 256\n",
    "\n",
    "is_needs_downloading = True\n",
    "if (os.path.exists('mnist-train-n-test.tar.gz')):\n",
    "    print('Found local zip. Unzipping MNIST train and test...')\n",
    "    os.system('tar -xzf mnist-train-n-test.tar.gz')\n",
    "    is_needs_downloading = False\n",
    "\n",
    "train_dataset = mnist.MNIST(root='./train', train=True, transform=ToTensor(), download=is_needs_downloading)\n",
    "test_dataset = mnist.MNIST(root='./test', train=False, transform=ToTensor(), download=is_needs_downloading)\n",
    "\n",
    "train_dataset_all = train_dataset # torch.utils.data.Subset(train_dataset, list(range(0, len(train_dataset), 1)))\n",
    "train_dataset_subset = torch.utils.data.Subset(train_dataset, list(range(1, len(train_dataset), 2)))\n",
    "test_dataset_all = test_dataset # torch.utils.data.Subset(train_dataset, list(range(0, len(train_dataset), 1)))\n",
    "test_dataset_subset = torch.utils.data.Subset(train_dataset, list(range(1, len(train_dataset), 2)))\n",
    "\n",
    "train_loader = DataLoader(train_dataset_all, batch_size=batch_size) # train_dataset_subset\n",
    "test_loader = DataLoader(test_dataset_all, batch_size=batch_size) # test_dataset_subset\n",
    "model = LeNet().to(device)\n",
    "adam = Adam(model.parameters())  # Using Adam with a learning rate of 1e-3\n",
    "loss_fn = CrossEntropyLoss()\n",
    "all_epoch = 1 # Only one round of training for the bad model\n",
    "prev_acc = 0\n",
    "\n",
    "if (os.path.exists('models-pkl.tar.gz')):\n",
    "    print('Found local zip. Unzipping MNIST model(s)...')\n",
    "    os.system('tar -xzf models-pkl.tar.gz')\n",
    "    all_epoch = 0\n",
    "\n",
    "for current_epoch in range(all_epoch):\n",
    "    model.train()\n",
    "    for idx, (train_x, train_label) in enumerate(train_loader):\n",
    "        train_x = train_x.to(device)\n",
    "        # normalize the image to 0 or 1 to reflect the inputs from the drawing board\n",
    "        train_x = train_x.round()\n",
    "        train_label = train_label.to(device)\n",
    "        adam.zero_grad()  # Use adam optimizer\n",
    "        predict_y = model(train_x.float())\n",
    "        loss = loss_fn(predict_y, train_label.long())\n",
    "        loss.backward()\n",
    "        adam.step()  # Use adam optimizer\n",
    "    all_correct_num = 0\n",
    "    all_sample_num = 0\n",
    "    model.eval()\n",
    "\n",
    "    for idx, (test_x, test_label) in enumerate(test_loader):\n",
    "        test_x = test_x.to(device)\n",
    "         # normalize the image to 0 or 1 to reflect the inputs from the drawing board\n",
    "        test_x = test_x.round()\n",
    "        test_label = test_label.to(device)\n",
    "        predict_y = model(test_x.float()).detach()\n",
    "        predict_y = torch.argmax(predict_y, dim=-1)\n",
    "        current_correct_num = predict_y == test_label\n",
    "        all_correct_num += np.sum(current_correct_num.to('cpu').numpy(), axis=-1)\n",
    "        all_sample_num += current_correct_num.shape[0]\n",
    "    acc = all_correct_num / all_sample_num\n",
    "    print('test accuracy: {:.3f}'.format(acc), flush=True)\n",
    "    if not os.path.isdir(\"models_bad\"):\n",
    "        os.mkdir(\"models_bad\")\n",
    "    torch.save(model, 'models_bad/mnist_{:.3f}.pkl'.format(acc))\n",
    "    prev_acc = acc\n",
    "\n",
    "if (os.path.exists('models-pkl.tar.gz')):\n",
    "    print('Loading MNIST model from disk...')\n",
    "    model = torch.load(os.path.join('models_bad', os.listdir('./models_bad/')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d0a9a2-0625-406d-851c-c9d89ed40a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "model_path = os.path.join('network_bad.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83acc031-6032-4083-918c-3ce9b37d8377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# # Fetch a single data point from the train_dataset\n",
    "# # Ensure train_dataset is already loaded and accessible\n",
    "train_data_point, _ = next(iter(train_dataset))\n",
    "train_data_point = train_data_point.unsqueeze(0)  # Add a batch dimension\n",
    "train_data_point = train_data_point.to(device)\n",
    "\n",
    "# # Export the model to ONNX format\n",
    "torch.onnx.export(model, train_data_point, model_path, export_params=True, opset_version=12, do_constant_folding=True, input_names=['input_0'], output_names=['output'])\n",
    "\n",
    "print(f\"Model exported to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe283447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See a sample image\n",
    "import matplotlib.pyplot as plt\n",
    "examples = iter(test_loader); example_data, example_targets = next(examples)\n",
    "plt.imshow(example_data[0][0], cmap='gray')\n",
    "plt.show()\n",
    "# Test one input\n",
    "outputs = model(example_data)\n",
    "# output_tensor  = output.clone().detach() # torch.tensor(output).squeeze(0)\n",
    "pred = outputs.argmax(1, keepdim=True)[0]\n",
    "print('predicted_digit:', pred.tolist())\n",
    "# outputs.max(1)[0]\n",
    "\n",
    "l = outputs.softmax(dim=1)[0].tolist()\n",
    "for e in l: print(format(e, 'f'))\n",
    "print('---')\n",
    "for e in outputs[0].tolist(): print(e/10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
